# AegiMem Distributed Architecture Design

## Overview

AegiMem í”„ë¡œì íŠ¸ë¥¼ **2ê°œì˜ ë…ë¦½ì ì¸ Agent**ë¡œ ë¶„ë¦¬í•˜ì—¬ êµ¬í˜„í•©ë‹ˆë‹¤:

1. **Memory Test Agent**: CXL ì„œë²„(GNR-CRB)ì—ì„œ ì‹¤ì œ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
2. **RL Policy Agent**: ë¡œì»¬ ê°œë°œ ë¨¸ì‹ ì—ì„œ ê°•í™”í•™ìŠµ ìˆ˜í–‰

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RL Policy Agent (ë¡œì»¬ ê°œë°œ ë¨¸ì‹ )                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   DQN       â”‚  â”‚    PPO      â”‚                  â”‚
â”‚  â”‚  Agent      â”‚  â”‚   Agent     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚                â”‚                          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                  â”‚                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚         â”‚  Policy Manager â”‚                         â”‚
â”‚         â”‚  - Action ì„ íƒ   â”‚                         â”‚
â”‚         â”‚  - í•™ìŠµ ìˆ˜í–‰     â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                  â”‚                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚         â”‚ Experience      â”‚                         â”‚
â”‚         â”‚ Buffer (JSONL)  â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                  â”‚                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚         â”‚  REST Client    â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTP POST
                   â”‚ {"operation": 0, "pattern": 0xAA}
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory Test Agent (GNR-CRB ì„œë²„)                    â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚         â”‚  REST Server   â”‚                          â”‚
â”‚         â”‚  (bottle.py)   â”‚                          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                  â”‚                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚         â”‚  Test Executor  â”‚                         â”‚
â”‚         â”‚  - devdax I/O   â”‚                         â”‚
â”‚         â”‚  - CE monitor   â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                  â”‚                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚         â”‚ DevDaxInterface â”‚                         â”‚
â”‚         â”‚ DPATranslator   â”‚                         â”‚
â”‚         â”‚ CECountMonitor  â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            [CXL Memory Device]
```

## Component Details

### 1. RL Policy Agent (ë¡œì»¬ ë¨¸ì‹ )

**ìœ„ì¹˜**: `/home/dhkang/cxl_memory_rl_project/src/rl_agent/`

**ì—­í• **:
- ê°•í™”í•™ìŠµ policy í•™ìŠµ ë° ê´€ë¦¬
- Action ì„ íƒ ë° ì „ì†¡
- Experience ìˆ˜ì§‘ ë° ì €ì¥
- í•™ìŠµ ë°ì´í„° ë¶„ì„

**ì£¼ìš” ì»´í¬ë„ŒíŠ¸**:

```python
# src/rl_agent/policy_manager.py
class PolicyManager:
    """
    RL policy ê´€ë¦¬ì
    - DQN, PPO ì•Œê³ ë¦¬ì¦˜ í†µí•©
    - Action ì„ íƒ
    - í•™ìŠµ ìŠ¤ì¼€ì¤„ë§
    """

    def __init__(self, algorithm='dqn'):
        if algorithm == 'dqn':
            self.agent = DQNAgent(...)
        elif algorithm == 'ppo':
            self.agent = PPOAgent(...)

    def select_action(self, state):
        """Current policyë¡œ action ì„ íƒ"""

    def train_step(self):
        """Experience bufferì—ì„œ ìƒ˜í”Œë§í•˜ì—¬ í•™ìŠµ"""

# src/rl_agent/dqn_agent.py
class DQNAgent:
    """
    Deep Q-Network Agent
    - Off-policy í•™ìŠµ
    - Experience replay
    - Target network
    """

# src/rl_agent/ppo_agent.py
class PPOAgent:
    """
    Proximal Policy Optimization Agent
    - On-policy í•™ìŠµ
    - Actor-Critic
    - Clipped surrogate objective
    """

# src/rl_agent/experience_buffer.py
class ExperienceBuffer:
    """
    JSONL ê¸°ë°˜ experience ì €ì¥
    - ì˜êµ¬ ë³´ì¡´
    - ë¶„ì„ ìš©ì´
    """

    def add(self, state, action, reward, next_state, done):
        with open(self.file_path, 'a') as f:
            f.write(json.dumps({
                'timestamp': time.time(),
                'state': state,
                'action': action,
                'reward': reward,
                'next_state': next_state,
                'done': done
            }) + '\n')

# src/rl_agent/memory_agent_client.py
class MemoryAgentClient:
    """
    Memory Test Agentì™€ í†µì‹ 
    """

    def __init__(self, base_url='http://gnr-crb:8000'):
        self.base_url = base_url

    def execute_action(self, action):
        """Action ì „ì†¡ ë° ê²°ê³¼ ìˆ˜ì‹ """
        response = requests.post(
            f'{self.base_url}/api/execute',
            json=action
        )
        return response.json()
```

**í•„ìš” íŒ¨í‚¤ì§€**:
- PyTorch ë˜ëŠ” TensorFlow (RL ì•Œê³ ë¦¬ì¦˜)
- NumPy (ìˆ˜ì¹˜ ê³„ì‚°)
- pandas (ë°ì´í„° ë¶„ì„)
- matplotlib (ì‹œê°í™”)
- requests (HTTP í´ë¼ì´ì–¸íŠ¸)

### 2. Memory Test Agent (GNR-CRB ì„œë²„)

**ìœ„ì¹˜**: `/tmp/memory_test_agent/` (GNR-CRB ì„œë²„)

**ì—­í• **:
- REST API ì„œë²„ ìš´ì˜
- ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- CE count ìˆ˜ì§‘
- ê²°ê³¼ ë¦¬í¬íŠ¸

**ì£¼ìš” ì»´í¬ë„ŒíŠ¸**:

```python
# memory_test_agent.py (ë‹¨ì¼ íŒŒì¼)
import bottle
from bottle import route, run, request
import json
import os
import subprocess
import time

# DevDax, DPA translator, CE monitor import
# (ê°™ì€ ë””ë ‰í† ë¦¬ì— ë³µì‚¬ëœ íŒŒì¼ë“¤)

@route('/api/execute', method='POST')
def execute_action():
    """
    RL Agentë¡œë¶€í„° action ë°›ì•„ì„œ ì‹¤í–‰

    Request:
    {
        "operation_type": 0-5,
        "pattern": 0x00-0xFF,
        "start_dram": {"rank": 0, "bg": 0, "ba": 0, "row": 0, "col": 0},
        "end_dram": {"rank": 0, "bg": 0, "ba": 0, "row": 100, "col": 100}
    }

    Response:
    {
        "ce_delta": 5,
        "execution_time": 1.23,
        "status": "success",
        "timestamp": "2025-01-13T10:30:00"
    }
    """
    try:
        action = request.json

        # CE count ì´ˆê¸°ê°’
        ce_before = ce_monitor.get_ce_count()
        start_time = time.time()

        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        devdax.execute_pattern_test(
            operation_type=action['operation_type'],
            pattern_byte=action['pattern'],
            start_dram=action['start_dram'],
            end_dram=action['end_dram']
        )

        # CE count ìµœì¢…ê°’
        ce_after = ce_monitor.get_ce_count()
        execution_time = time.time() - start_time

        return {
            'ce_delta': ce_after - ce_before,
            'execution_time': execution_time,
            'status': 'success',
            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%S')
        }

    except Exception as e:
        return {
            'status': 'error',
            'error': str(e),
            'timestamp': time.strftime('%Y-%m-%dT%H:%M:%S')
        }

@route('/api/status', method='GET')
def get_status():
    """Agent ìƒíƒœ í™•ì¸"""
    return {
        'status': 'running',
        'device': '/dev/dax0.0',
        'ce_count': ce_monitor.get_ce_count()
    }

if __name__ == '__main__':
    # DevDax, CE monitor ì´ˆê¸°í™”
    global devdax, ce_monitor

    devdax = DevDaxInterface(
        device_path='/dev/dax0.0',
        dpa_translator=translator,
        ce_monitor=ce_monitor
    )

    ce_monitor = CECountMonitor(device='mem0')

    print("Memory Test Agent starting on port 8000...")
    run(host='0.0.0.0', port=8000)
```

**í•„ìš” íŒŒì¼** (GNR-CRBë¡œ ë³µì‚¬):
- `bottle.py` (ë‹¨ì¼ íŒŒì¼, 70KB)
- `memory_test_agent.py`
- `devdax_interface.py`
- `dpa_translator.py`
- `ce_count_monitor.py`
- `dpa_mapping.csv` (ìˆ˜ì§‘ëœ ë§¤í•‘ ë°ì´í„°)

**ì˜ì¡´ì„±**: Python 3.10.12 í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ

## Communication Protocol

### REST API Specification

#### 1. Execute Action

**Endpoint**: `POST /api/execute`

**Request**:
```json
{
    "operation_type": 0,
    "pattern": 170,
    "start_dram": {
        "rank": 0,
        "bg": 0,
        "ba": 0,
        "row": 0,
        "col": 0
    },
    "end_dram": {
        "rank": 0,
        "bg": 0,
        "ba": 0,
        "row": 100,
        "col": 100
    }
}
```

**Response**:
```json
{
    "ce_delta": 5,
    "execution_time": 1.234,
    "status": "success",
    "timestamp": "2025-01-13T10:30:00",
    "metadata": {
        "ce_before": 100,
        "ce_after": 105
    }
}
```

#### 2. Get Status

**Endpoint**: `GET /api/status`

**Response**:
```json
{
    "status": "running",
    "device": "/dev/dax0.0",
    "ce_count": 105,
    "uptime": 3600
}
```

## Data Flow

### 1. Training Loop

```python
# RL Agent (ë¡œì»¬)
for episode in range(num_episodes):
    state = env.reset()
    done = False

    while not done:
        # 1. Action ì„ íƒ
        action = policy.select_action(state)

        # 2. Memory Agentì— ì „ì†¡
        result = memory_client.execute_action(action)

        # 3. Reward ê³„ì‚°
        reward = result['ce_delta']

        # 4. Experience ì €ì¥
        experience_buffer.add(state, action, reward, next_state, done)

        # 5. í•™ìŠµ
        if buffer.size() > batch_size:
            policy.train_step()

        state = next_state
```

### 2. Experience Storage

**íŒŒì¼ ìœ„ì¹˜**: `data/experiences/experiment_001.jsonl`

**Format**:
```json
{"timestamp": 1705132200.123, "state": {...}, "action": {...}, "reward": 5, "next_state": {...}, "done": false}
{"timestamp": 1705132205.456, "state": {...}, "action": {...}, "reward": 3, "next_state": {...}, "done": false}
{"timestamp": 1705132210.789, "state": {...}, "action": {...}, "reward": 0, "next_state": {...}, "done": true}
```

## Project Structure

```
cxl_memory_rl_project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rl_agent/                    # RL Policy Agent (ë¡œì»¬)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ policy_manager.py        # Policy ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py             # DQN êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ ppo_agent.py             # PPO êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ experience_buffer.py     # JSONL ë²„í¼
â”‚   â”‚   â”œâ”€â”€ memory_agent_client.py   # REST í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â””â”€â”€ training_loop.py         # í•™ìŠµ ë£¨í”„
â”‚   â”‚
â”‚   â”œâ”€â”€ memory_agent/                # Memory Test Agent (GNR-CRB)
â”‚   â”‚   â”œâ”€â”€ memory_test_agent.py     # Main server
â”‚   â”‚   â”œâ”€â”€ devdax_interface.py      # DevDax ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ dpa_translator.py        # DPA ë³€í™˜
â”‚   â”‚   â””â”€â”€ ce_count_monitor.py      # CE count ìˆ˜ì§‘
â”‚   â”‚
â”‚   â””â”€â”€ common/                      # ê³µí†µ ëª¨ë“ˆ
â”‚       â”œâ”€â”€ state_representation.py  # State ì •ì˜
â”‚       â””â”€â”€ action_space.py          # Action space ì •ì˜
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ experiences/                 # JSONL experience files
â”‚   â”‚   â”œâ”€â”€ dqn_exp001.jsonl
â”‚   â”‚   â””â”€â”€ ppo_exp001.jsonl
â”‚   â”œâ”€â”€ models/                      # í•™ìŠµëœ ëª¨ë¸
â”‚   â””â”€â”€ dpa_mapping/                 # DPA ë§¤í•‘ ë°ì´í„°
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ dqn_config.yaml
â”‚   â””â”€â”€ ppo_config.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy_memory_agent.sh      # GNR-CRB ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ start_training_dqn.sh
â”‚   â””â”€â”€ start_training_ppo.sh
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ DISTRIBUTED_ARCHITECTURE.md  # ì´ ë¬¸ì„œ
    â”œâ”€â”€ DQN_IMPLEMENTATION.md
    â””â”€â”€ PPO_IMPLEMENTATION.md
```

## Deployment

### Memory Test Agent ë°°í¬

```bash
# ë¡œì»¬ì—ì„œ
cd /home/dhkang/cxl_memory_rl_project

# 1. bottle.py ë‹¤ìš´ë¡œë“œ
wget https://raw.githubusercontent.com/bottlepy/bottle/master/bottle.py -P src/memory_agent/

# 2. GNR-CRBë¡œ ì „ì†¡
scp -r src/memory_agent user@gnr-crb:/tmp/
scp data/dpa_mapping/dpa_mapping.csv user@gnr-crb:/tmp/memory_agent/

# 3. GNR-CRBì—ì„œ ì‹¤í–‰
ssh user@gnr-crb
cd /tmp/memory_agent
python3 memory_test_agent.py
# Memory Test Agent starting on port 8000...
```

### RL Policy Agent ì‹¤í–‰

```bash
# ë¡œì»¬ì—ì„œ
cd /home/dhkang/cxl_memory_rl_project

# DQN í•™ìŠµ
python3 src/rl_agent/training_loop.py --algorithm dqn --episodes 1000

# PPO í•™ìŠµ
python3 src/rl_agent/training_loop.py --algorithm ppo --episodes 1000
```

## RL Algorithm Comparison

| Feature | DQN | PPO |
|---------|-----|-----|
| **Type** | Off-policy | On-policy |
| **Experience Replay** | âœ… Yes | âŒ No |
| **Sample Efficiency** | ğŸŸ¢ High | ğŸŸ¡ Medium |
| **Stability** | ğŸŸ¡ Medium | ğŸŸ¢ High |
| **Continuous Action** | âŒ No | âœ… Yes |
| **Implementation** | ğŸŸ¢ Simple | ğŸŸ¡ Complex |
| **ìš°ë¦¬ í”„ë¡œì íŠ¸** | Discrete (1536 actions) | Discrete (1536 actions) |

**Both suitable for our discrete action space!**

## State Representation

```python
state = {
    # í˜„ì¬ê¹Œì§€ í…ŒìŠ¤íŠ¸í•œ íŒ¨í„´ ì •ë³´
    'tested_patterns': [0xAA, 0x55, ...],  # ìµœê·¼ Nê°œ

    # ê° operationë³„ íš¨ìœ¨ì„±
    'operation_efficiency': [0.8, 0.6, ...],  # 6ê°œ

    # í˜„ì¬ ë©”ëª¨ë¦¬ ì˜ì—­ ìƒíƒœ
    'current_region': {
        'rank': 0, 'bg': 0, 'ba': 0,
        'row_range': (0, 1000)
    },

    # ëˆ„ì  í†µê³„
    'total_ce_found': 123,
    'total_tests': 456,
    'avg_ce_per_test': 0.27
}
```

## Action Space

```python
action = {
    'operation_type': 0-5,  # 6 operations
    'pattern': 0x00-0xFF,   # 256 patterns

    # Total: 6 Ã— 256 = 1,536 discrete actions
}

# Mapping
action_id = operation_type * 256 + pattern
# Example: action_id = 0 * 256 + 170 = 170
#          â†’ [^(W 0xAA), ^(R 0xAA)]
```

## Next Steps

1. âœ… Architecture design complete
2. â­ï¸ Implement CE count collection mechanism
3. â­ï¸ Implement Memory Test Agent
4. â­ï¸ Implement DQN Agent
5. â­ï¸ Implement PPO Agent
6. â­ï¸ Analyze collected DPA mapping data
7. â­ï¸ Integration testing
8. â­ï¸ Real hardware deployment

## Open Questions

1. **State representation ì„¸ë¶€ì‚¬í•­**:
   - ì–´ë–¤ ì •ë³´ë¥¼ stateì— í¬í•¨?
   - State ì°¨ì›ì€?

2. **Reward shaping**:
   - CE deltaë§Œ?
   - ì‹œê°„ íŒ¨ë„í‹°?
   - Exploration bonus?

3. **Episode ì •ì˜**:
   - Episode ì¢…ë£Œ ì¡°ê±´?
   - ëª‡ step per episode?

4. **Hyperparameters**:
   - Learning rate
   - Batch size
   - Network architecture

ì´ëŸ¬í•œ ì„¸ë¶€ì‚¬í•­ì€ êµ¬í˜„í•˜ë©´ì„œ ê²°ì •í•˜ê² ìŠµë‹ˆë‹¤!
